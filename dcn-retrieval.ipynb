{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-21T03:08:03.090352Z","iopub.execute_input":"2022-02-21T03:08:03.090675Z","iopub.status.idle":"2022-02-21T03:08:03.128122Z","shell.execute_reply.started":"2022-02-21T03:08:03.090595Z","shell.execute_reply":"2022-02-21T03:08:03.127256Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# !pip install tensorflow_recommenders","metadata":{"execution":{"iopub.status.busy":"2022-02-21T03:08:29.155576Z","iopub.execute_input":"2022-02-21T03:08:29.156024Z","iopub.status.idle":"2022-02-21T03:08:59.314660Z","shell.execute_reply.started":"2022-02-21T03:08:29.155985Z","shell.execute_reply":"2022-02-21T03:08:59.313914Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\nimport tensorflow_recommenders as tfrs","metadata":{"execution":{"iopub.status.busy":"2022-02-21T03:09:19.347711Z","iopub.execute_input":"2022-02-21T03:09:19.347977Z","iopub.status.idle":"2022-02-21T03:09:20.208572Z","shell.execute_reply.started":"2022-02-21T03:09:19.347951Z","shell.execute_reply":"2022-02-21T03:09:20.207672Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Ratings data.\nratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n# Features of all the available movies.\nmovies = tfds.load(\"movielens/100k-movies\", split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2022-02-21T03:46:43.737664Z","iopub.execute_input":"2022-02-21T03:46:43.738014Z","iopub.status.idle":"2022-02-21T03:46:43.851430Z","shell.execute_reply.started":"2022-02-21T03:46:43.737977Z","shell.execute_reply":"2022-02-21T03:46:43.850724Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"ratings = ratings.map(lambda x: {\n    \"movie_title\": x[\"movie_title\"],\n    \"user_id\": x[\"user_id\"],\n})\nmovies = movies.map(lambda x: x[\"movie_title\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-21T03:47:01.726143Z","iopub.execute_input":"2022-02-21T03:47:01.726943Z","iopub.status.idle":"2022-02-21T03:47:01.746032Z","shell.execute_reply.started":"2022-02-21T03:47:01.726904Z","shell.execute_reply":"2022-02-21T03:47:01.745102Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(42)\nshuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n\ntrain = shuffled.take(80_000)\ntest = shuffled.skip(80_000).take(20_000)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T03:47:09.320112Z","iopub.execute_input":"2022-02-21T03:47:09.320736Z","iopub.status.idle":"2022-02-21T03:47:09.362147Z","shell.execute_reply.started":"2022-02-21T03:47:09.320699Z","shell.execute_reply":"2022-02-21T03:47:09.361477Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"movie_titles = movies.batch(1_000)\nuser_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n\nunique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\nunique_user_ids = np.unique(np.concatenate(list(user_ids)))\n\nunique_movie_titles[:10]","metadata":{"execution":{"iopub.status.busy":"2022-02-21T03:47:29.446699Z","iopub.execute_input":"2022-02-21T03:47:29.447287Z","iopub.status.idle":"2022-02-21T03:47:37.298949Z","shell.execute_reply.started":"2022-02-21T03:47:29.447238Z","shell.execute_reply":"2022-02-21T03:47:37.297892Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"embedding_dimension = 32\n\nuser_model = tf.keras.Sequential([\n  tf.keras.layers.StringLookup(\n      vocabulary=unique_user_ids, mask_token=None),\n  # We add an additional embedding to account for unknown tokens.\n  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n])","metadata":{"execution":{"iopub.status.busy":"2022-02-21T03:47:42.502536Z","iopub.execute_input":"2022-02-21T03:47:42.502822Z","iopub.status.idle":"2022-02-21T03:47:42.518459Z","shell.execute_reply.started":"2022-02-21T03:47:42.502793Z","shell.execute_reply":"2022-02-21T03:47:42.517571Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"movie_model = tf.keras.Sequential([\n  tf.keras.layers.StringLookup(\n      vocabulary=unique_movie_titles, mask_token=None),\n  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n])","metadata":{"execution":{"iopub.status.busy":"2022-02-21T03:47:47.772203Z","iopub.execute_input":"2022-02-21T03:47:47.772887Z","iopub.status.idle":"2022-02-21T03:47:47.787653Z","shell.execute_reply.started":"2022-02-21T03:47:47.772826Z","shell.execute_reply":"2022-02-21T03:47:47.786694Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"metrics = tfrs.metrics.FactorizedTopK(\n  candidates=movies.batch(128).map(movie_model)\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T03:47:55.928446Z","iopub.execute_input":"2022-02-21T03:47:55.928941Z","iopub.status.idle":"2022-02-21T03:47:55.976657Z","shell.execute_reply.started":"2022-02-21T03:47:55.928875Z","shell.execute_reply":"2022-02-21T03:47:55.975787Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"task = tfrs.tasks.Retrieval(\n  metrics=metrics\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T03:48:03.910121Z","iopub.execute_input":"2022-02-21T03:48:03.910401Z","iopub.status.idle":"2022-02-21T03:48:03.918935Z","shell.execute_reply.started":"2022-02-21T03:48:03.910372Z","shell.execute_reply":"2022-02-21T03:48:03.918051Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"class MovielensModel(tfrs.Model):\n\n    def __init__(self, user_model, movie_model):\n        super().__init__()\n        self.movie_model: tf.keras.Model = movie_model\n        self.user_model: tf.keras.Model = user_model\n        self.task: tf.keras.layers.Layer = task\n\n    def compute_loss(self, features: ratings, training=False) -> tf.Tensor:\n        # We pick out the user features and pass them into the user model.\n        user_embeddings = self.user_model(features[\"user_id\"])\n        # And pick out the movie features and pass them into the movie model,\n        # getting embeddings back.\n        positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n\n        # The task computes the loss and the metrics.\n        return self.task(user_embeddings, positive_movie_embeddings)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T04:00:55.353092Z","iopub.execute_input":"2022-02-21T04:00:55.353543Z","iopub.status.idle":"2022-02-21T04:00:55.360185Z","shell.execute_reply.started":"2022-02-21T04:00:55.353507Z","shell.execute_reply":"2022-02-21T04:00:55.359619Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"model = MovielensModel(user_model, movie_model)\nmodel.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))","metadata":{"execution":{"iopub.status.busy":"2022-02-21T04:01:00.224531Z","iopub.execute_input":"2022-02-21T04:01:00.224829Z","iopub.status.idle":"2022-02-21T04:01:00.240260Z","shell.execute_reply.started":"2022-02-21T04:01:00.224797Z","shell.execute_reply":"2022-02-21T04:01:00.239535Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"cached_train = train.shuffle(100_000).batch(8192).cache()\ncached_test = test.batch(4096).cache()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T04:01:16.540403Z","iopub.execute_input":"2022-02-21T04:01:16.540758Z","iopub.status.idle":"2022-02-21T04:01:16.548655Z","shell.execute_reply.started":"2022-02-21T04:01:16.540708Z","shell.execute_reply":"2022-02-21T04:01:16.547849Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"result = model.evaluate(cached_test, return_dict=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T04:03:13.262100Z","iopub.execute_input":"2022-02-21T04:03:13.262650Z","iopub.status.idle":"2022-02-21T04:03:17.544392Z","shell.execute_reply.started":"2022-02-21T04:03:13.262615Z","shell.execute_reply":"2022-02-21T04:03:17.543785Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"result_items = result.items()\nfor item in result_items:\n    print(item)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T04:05:21.016051Z","iopub.execute_input":"2022-02-21T04:05:21.016339Z","iopub.status.idle":"2022-02-21T04:05:21.021938Z","shell.execute_reply.started":"2022-02-21T04:05:21.016306Z","shell.execute_reply":"2022-02-21T04:05:21.021166Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# Create a model that takes in raw query features, and\nindex = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n# recommends movies out of the entire movies dataset.\nindex.index_from_dataset(\n  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n)\n\n# Get recommendations.\n_, titles = index(tf.constant([\"32\"]))\nprint(f\"Recommendations for user 32: {titles[0, :3]}\")","metadata":{"execution":{"iopub.status.busy":"2022-02-21T04:06:25.425995Z","iopub.execute_input":"2022-02-21T04:06:25.426433Z","iopub.status.idle":"2022-02-21T04:06:25.538109Z","shell.execute_reply.started":"2022-02-21T04:06:25.426401Z","shell.execute_reply":"2022-02-21T04:06:25.535773Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}